{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set some path usefult in this application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path containing all names: .\\data\\names.txt\n",
      "Folder that contains the saved network: .\\model\n"
     ]
    }
   ],
   "source": [
    "PRJ_PATH = '.'\n",
    "DATA_PATH = os.path.join(PRJ_PATH, 'data', 'names.txt')\n",
    "MODEL_FLD = os.path.join(PRJ_PATH, 'model')\n",
    "\n",
    "print(f'Path containing all names: {DATA_PATH}')\n",
    "print(f'Folder that contains the saved network: {MODEL_FLD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create 2 simple dictionaries that maps an integer to a letter and vice versa\n",
    "\n",
    "char2int : char -> integer <br />\n",
    "int2char : integer -> char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2int = {'.': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7,\n",
    "            'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14,\n",
    "            'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21,\n",
    "            'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
    "int2char = inv_map = {v: k for k, v in char2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the folder where the model will be saved\n",
    "if 'model' not in os.listdir(PRJ_PATH):\n",
    "    os.makedirs(os.path.join(PRJ_PATH, 'model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 names:\n",
      "brycen\toakley\tisabel\testella\tenoch\n",
      "natasha\tbrynn\tjayde\tkyla\tsophie\n"
     ]
    }
   ],
   "source": [
    "# Loading the file containing the names and prepocessing them\n",
    "with open(DATA_PATH, 'r') as f:\n",
    "    names = f.readlines()\n",
    "    names = [s.strip().lower() for s in names]\n",
    "\n",
    "print('First 10 names:')\n",
    "print('\\t'.join(names[:5]))\n",
    "print('\\t'.join(names[5:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDatataset(Dataset):\n",
    "    def __init__(self, names=None):\n",
    "        # Names\n",
    "        self.names = names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fix the length to 11\n",
    "        x_str = (self.names[idx].lower() + '.'*11)[:11]\n",
    "        # Create the expected output for x_str\n",
    "        y_str = x_str[1:] + \".\"\n",
    "\n",
    "        x = torch.zeros((11, 27))\n",
    "        y = torch.zeros(11)\n",
    "        for i, c in enumerate(x_str):\n",
    "            # Perform one-hot-encoding of each symbol\n",
    "            x[i, char2int[c]] = 1\n",
    "        for i, c in enumerate(y_str):\n",
    "            y[i] = char2int[c]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 27\n",
    "HIDDEN_SIZE = 216\n",
    "OUTPUT_SIZE = 27\n",
    "NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lstm(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(Lstm, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm1 = torch.nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = torch.nn.Linear(hidden_size, int(round(hidden_size/2, 0)))\n",
    "        self.fc2 = torch.nn.Linear(int(round(hidden_size/2, 0)), output_size)\n",
    "\n",
    "    def forward(self, X, states):\n",
    "        ht, ct = states\n",
    "        # LSTM\n",
    "        out, (ht, ct) = self.lstm1(X, (ht, ct))\n",
    "\n",
    "        # First FC layer\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        # Second FC layer\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out, (ht, ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 0.005\n",
    "GAMMA = 0.95\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Training on ' + (\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's instantiate the Dataset\n",
    "dataset = NameDatataset(names)\n",
    "# Let's instantiate the Loader\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the network\n",
    "model = Lstm(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE, NUM_LAYERS).to(device)\n",
    "# Instantiate the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# Instantiate the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "# Instantiate the learning rate scheduler\n",
    "sched = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=1, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    batch_loss = 0\n",
    "\n",
    "    h0 = torch.zeros((NUM_LAYERS, 1, HIDDEN_SIZE)).to(device)\n",
    "    c0 = torch.zeros((NUM_LAYERS, 1, HIDDEN_SIZE)).to(device)\n",
    "    for batch_id, (data, label) in enumerate(loader):\n",
    "        h, c = h0.detach().clone(), c0.detach().clone()\n",
    "\n",
    "        # First, push on the GPU all the tensors\n",
    "        data, label = data.to(device), label.to(device, dtype=torch.long)\n",
    "        # Empty the gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Get the output from the network\n",
    "        out, (h, c) = model(data, (h, c))\n",
    "        out = out.transpose(1, 2)\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(out, label)\n",
    "        # Perform the backpropagation\n",
    "        loss.backward()\n",
    "        # Perform the gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record the loss\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "    tot_loss = batch_loss / len(loader)\n",
    "    print(f'Epoch {epoch} -> ' +\n",
    "          f'Loss = {tot_loss:.6f}')\n",
    "\n",
    "    losses.append(tot_loss)\n",
    "    sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model in .\\model\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), os.path.join(MODEL_FLD, 'net.pt'))\n",
    "print(f'Saved model in {MODEL_FLD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(color=\"#989898\", zorder=0)\n",
    "\n",
    "plt.plot(list(range(len(losses))), losses, zorder=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to create a tensor that represents the word passed as argument\n",
    "def word2tensor(word, max_name_len):\n",
    "    w = torch.zeros((11, 27))\n",
    "    for i in range(len(word)):\n",
    "        w[i, char2int[word[i]]] = 1\n",
    "    for i in range(len(word), max_name_len):\n",
    "        w[i, 0] = 1\n",
    "    return torch.unsqueeze(w, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NAME_LEN = 11\n",
    "TOP_K_OPTIONS = 3\n",
    "NUM_NAMES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the first letter of the kind of name that you want generate\n",
    "NAMES_FIRST_LETTER = ['a', 'f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name generated!\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "h0 = torch.zeros((NUM_LAYERS, 1, HIDDEN_SIZE)).to(device)\n",
    "c0 = torch.zeros((NUM_LAYERS, 1, HIDDEN_SIZE)).to(device)\n",
    "\n",
    "names = []\n",
    "\n",
    "for letter in NAMES_FIRST_LETTER:\n",
    "    current_names = []\n",
    "    for _ in range(NUM_NAMES):\n",
    "        name = letter\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx in range(MAX_NAME_LEN):\n",
    "                # If last letter is the \"end\" character, terminate the generation\n",
    "                if name[-1] == '.': break\n",
    "\n",
    "                # Generate the tensor representing the name (till the last letter generated)\n",
    "                data = word2tensor(name, MAX_NAME_LEN).to(device)\n",
    "\n",
    "                # Generate new letter for the name\n",
    "                h, c = h0.detach().clone(), c0.detach().clone()\n",
    "                out, (h, c) = model(data, (h, c))\n",
    "\n",
    "                # Select the top-k generated letters\n",
    "                out = torch.squeeze(out, dim=0)\n",
    "                out = out[idx]\n",
    "                top_k_val, top_k_idx = torch.topk(out, TOP_K_OPTIONS)\n",
    "                top_k_idx = top_k_idx.cpu().numpy()\n",
    "\n",
    "                # From the top-k select with special distribution which is the next letter\n",
    "                # This is done to avoid having completely a deterministic name generation process\n",
    "                selector = np.random.rand()\n",
    "                if   selector >= 0.5:   choice = 0\n",
    "                elif selector >= 0.2:   choice = 1\n",
    "                else:                   choice = 2\n",
    "\n",
    "                # Appen to the name the new letter (or \"end\" character)\n",
    "                last_letter = int2char[top_k_idx[choice]]\n",
    "                if last_letter != \".\": name += last_letter\n",
    "                else:\n",
    "                    if idx > 2: name += last_letter\n",
    "\n",
    "        if name[-1] == '.': name = name[:-1]\n",
    "        current_names.append(name)\n",
    "\n",
    "    names.append((letter, current_names))\n",
    "print('Name generated!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names generated with starting letter \"a\":\n",
      "\n",
      "alexa          anablee        anas           alexandriah    alessan        \n",
      "arya           ares           aleja          alexan         alex           \n",
      "aleso          annaballa      ana            alinah         annabel        \n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Names generated with starting letter \"f\":\n",
      "\n",
      "farroyi        frarandol      frances        franco         frarin         \n",
      "frane          fishe          finnegenle     farbana        frediet        \n",
      "finnegan       fishel         fridahna       faita          farro          \n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for letter, names_list in names:\n",
    "    print(f'Names generated with starting letter \"{letter}\":\\n')\n",
    "\n",
    "    for curr_idx in range(0, NUM_NAMES-5, 5):\n",
    "        final_str = ''\n",
    "        for idx in range(curr_idx, curr_idx+5):\n",
    "            final_str += names_list[idx] + ' '*(15-len(names_list[idx]))\n",
    "        print(final_str)\n",
    "    print('\\n-------------------------------------------------------------------------\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2423b31adc4e5c7e619478db68d9c6947844c0ccd0ec8adf66ade40c69bbb33a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('NN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
